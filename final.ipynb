{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('newyorktimes.csv')\n",
    "df = df[df['publication_date'] >= '2019-01-01']\n",
    "\n",
    "# Handle NaN values\n",
    "df['title'] = df['title'].fillna('')\n",
    "df['body'] = df['body'].fillna('')\n",
    "# drop the rows having no body\n",
    "df = df[df['body'] != '']\n",
    "\n",
    "# Concatenating title and body\n",
    "df['title_body'] = df['title'] + ' ' + df['body']\n",
    "# Preprocessing\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_modeling(num_topics):\n",
    "    model = gensim.models.ldamodel.LdaModel(corpus=doc_term_matrix, id2word=dictionary, num_topics=num_topics, random_state=100, \n",
    "                                            chunksize=1000, passes=50)\n",
    "    coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence='c_v')\n",
    "    return coherencemodel.get_coherence()\n",
    "\n",
    "doc_clean = [clean(doc).split() for doc in tqdm(df['title_body'], desc=\"Cleaning Data\")] \n",
    "\n",
    "dictionary = corpora.Dictionary(doc_clean)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "\n",
    "# Number of CPUs to use for parallel processing. Adjust if necessary.\n",
    "num_cpus = 4 \n",
    "\n",
    "coherence_values = []\n",
    "with Pool(num_cpus) as pool:\n",
    "    coherence_values.extend(list(tqdm(pool.imap(topic_modeling, range(100, 201, 10)), desc=\"Topic Modeling\", total=11)))\n",
    "\n",
    "print(coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the coherence scores\n",
    "plt.plot(range(100, 201, 10), coherence_values)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
